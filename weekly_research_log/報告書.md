---
title: "報告書"
創建時間: "2025-12-19"
tags: 
week: " Week 46"
---
# 基於 WGAN-GP 的字體風格遷移研究

###### 校內報名前報告

## 研究動機

自從 ai 大模型問世造成轟動，我一直對相關領域有著極大的興趣。在訓練手法上，尤其對生成對抗網路(GAN)的設計著迷。其藉由兩個神經網路（生成器 G 與判別器 D）進行對抗學習，能有效解決傳統損失函數難以量化圖像「風格」與「真實感」的問題。我一直想要對其進行更深入的研究及應用，但直到進行此研究之前都沒有找到難度適合又有興趣的應用。  

恰巧近年來，隨著技術的進步以及設計個人化需求的增加，市面上及社群軟體討論中出現了多種英文字體的生成工具@。使用者只需手寫 26 個字母(和其他數字與符號)，便能自動生成完整的個人化字體。

然而，在中文字體領域卻鮮少看到類似的應用工具。中文字體因其筆畫結構複雜、字數龐大的特性，若要求使用者手寫數千個常用字(約為 4000 字)才能生成字體，實用性將大幅降低。因此，如何透過少量的手寫樣本，就能生成風格一致的完整中文字體，成為一個值得探索的技術挑戰。

本研究嘗試開發一套實用的中文字體生成工具，讓一般使用者也能在僅需要書寫少量文字的情況下就能生成屬於自己的字體。考量到中文字體生成的難度，研究初期將以英文與數字作為實驗對象，深入研究 GAN 的運作原理與參數設定並嘗試不同的資料處理及增強方式，並將實驗歸納之結論，進一步應用於中文字體的生成任務中，以期降低個人化中文字體的製作門檻。
## 目的
1. 建構基於 WGAN-GP 的字體生成模型
探討並實作 Wasserstein GAN with Gradient Penalty (WGAN-GP) 架構，以此解決傳統 GAN 在訓練過程中容易產生的模式崩塌（Mode Collapse）與梯度消失問題，建立一個穩定且高品質的字體圖像生成基礎模型。

2. 探討資料前處理與增強技術對泛化能力的影響
分析不同的數據增強策略（如隨機遮罩、幾何變換、平移縮放）對模型學習成效的影響。本研究將探討在缺乏大量成對訓練資料的情況下（主動移除部分資料），如何透過模擬缺損與變形，強迫模型學習字體的筆畫結構而非單純記憶像素，進而提升對陌生字符的生成品質。

3. 分析生成器瓶頸層（Bottleneck）特徵維度對生成效果之影響
研究生成器架構中「瓶頸層（Bottleneck）」的特徵圖尺寸對輸出結果的影響。探討在資訊壓縮過程中，不同程度的特徵壓縮率如何影響生成字體的「整體結構完整性」與「局部筆畫細節」，並試圖找出最佳的特徵維度設定。

4. 分析生成器層數對生成效果之影響
研究生成器架構中捲積網路的層數對輸出結果的影響。探討在生成文字時，是否越多的層數能帶來越精緻的效果。

5. 最佳化損失函數權重配置
探討像素損失（L1 Loss）與對抗損失（Adversarial Loss）之間的權重平衡。分析不同比例的參數權重如何影響生成字體的清晰度與風格真實感，以解決字體生成中常見的模糊或結構扭曲問題。

6. 評估跨語言字體生成之可行性
以英文與數字作為實驗對照組，驗證最佳化後的模型架構是否能遷移至結構更為複雜的中文字體任務。評估在「少樣本（Few-shot）」情境下，模型是否能依據少量手寫中文字樣本，推論並生成風格一致的其他漢字。
## 設備

### 硬體
Google colab L4 GPU @
### 軟體
Python
Pytorch
PIL
## 方法及過程

### 研究流程

1. 文獻探討
2. 資料集製作與配對
3. 以數字做嘗試，建立最小的可用GAN架構
4. 引入英文字母，並透過GAN文獻經驗尋找一個效果恰當的超參數
5. 針對不同的研究目標，控制變因進行實驗
6. 針對相同的目標，使用不同字體進行實驗
7. 總結上述實驗並應用至中文字體生成
8. 總結所有實驗
### 文獻探討

[zi2zi](https://kaonashi-tyc.github.io/2017/04/06/zi2zi.html)
是一個基於 pix2pix 的中文字體生成實踐，

四、 Pix2pix

(一) 概敘：Pix2pix 是一種Conditional GAN(CGAN)，主要用於圖像和圖像之間的映射，稱

為圖像轉譯。

(二) 方法：pix2pix有著CGAN的特色，運行GAN的過程中有輸入圖片，而不是單純透

過雜訊向量進行訓練。因此Pix2pix能夠在輸入圖片的基礎上進行訓練。

(三) U-Net 結構：是一個優化Encoder-Decoder的跳躍式連結。由於Encoder-Decoder結構

具有對稱性，故第i層和第n-i層大小大致相同。U-Net結構就是將第i層和第n-i層直

接連接起來，目的是確保輸入圖片和生成圖片的相似性。

(四) 特性：由於Pix2pix是圖像的一對一映射，我們在訓練時必須採用成對的(Paired)資料

進行訓練。也因此，pix2pix應用的範圍受到訓練集的限制，必須有充足的訓練集才能

產生有意義的輸出結果。

  

應用在中文字體生成的實踐

其特點在於 同時學習多種字形

以及一對多的類別嵌入

![alt text](../re/img/pix2pix.png)

  

https://twsf.ntsec.gov.tw/activity/race-1/58/pdf/NPHSF2018-052511.pdf

運用GAN實現字體風格轉換

其實現方式基本上與 zi2zi 一致

  

https://openaccess.thecvf.com/content/WACV2021/papers/Wen_Handwritten_Chinese_Font_Generation_With_Collaborative_Stroke_Refinement_WACV_2021_paper.pdf

其引入了 粗體分支 以及字體變形來處理 使訓練資料降到 750 個

  

![alt text](img/image.png)

![alt text](img/image2.png)

  

上述皆有透過預訓練資料預先訓練模型

  

本研究則專注在 GAN 模型本身的調整以及字體變形。並將字體生成視為一個字體的轉換任務，所以並沒有使用欲訓練資料對模型進行訓練

  

## 研究方法

### 資料處理

  

這份研究方法是根據你的需求，將 PyTorch 程式碼中的邏輯轉化為學術報告的章節。我將內容分為九個部分，語言風格採用正式的論文口吻。

你可以直接將這些文字複製到你的報告中，若有需要補充圖片（如架構圖），我在文字中也做了提示。

第三章 研究方法

本研究提出一套基於生成對抗網路的字體風格遷移系統，旨在透過成對的字體圖像訓練，使模型學習從標準印刷字體（Source）轉換至特定手寫風格（Target）的映射關係。詳細方法論述如下：

3.1 模型架構選用：WGAN-GP 的優勢

在生成對抗網路（GAN）的發展歷程中，原始 GAN 常面臨訓練不穩定、梯度消失（Vanishing Gradient）以及模式崩塌（Mode Collapse）等問題，導致生成器產出單一或品質低落的樣本。

為了克服上述困難，本研究採用 Wasserstein GAN with Gradient Penalty (WGAN-GP) 作為核心架構。

Wasserstein 距離： 不同於原始 GAN 使用 JS 散度（Jensen-Shannon Divergence），WGAN 利用 Earth-Mover (EM) 距離來衡量真實分佈與生成分佈的差異。即使兩個分佈不重疊，EM 距離仍能提供有意義的梯度，引導生成器持續學習。

梯度懲罰 (Gradient Penalty)： 為了滿足 Wasserstein 距離所需的 1-Lipschitz 連續性限制，WGAN-GP 摒棄了早期 WGAN 直接裁切權重（Weight Clipping）的做法（該做法易導致參數兩極化），改為在損失函數中加入梯度懲罰項，確保判別器的梯度範數維持在 1 附近，顯著提升了訓練的穩定性與收斂速度。

  

3.2 資料處理：成對圖像生成

本研究不使用現成的圖像資料庫，而是利用 Python 的影像處理函式庫（PIL），直接讀取字體文件（.ttf / .otf）進行即時渲染。

圖像規格： 將來源字體（如 Times New Roman）與目標字體（如手寫字體）統一渲染為64×64 像素的灰階圖像。

成對映射： 建立「一一對應（One-to-One mapping）」的訓練資料，即輸入一張標準的「A」，模型需對應輸出風格化後的「A」。這種成對監督式學習有助於模型快速掌握字體的骨架結構。

本次研究的字體有以下幾個

  

3.3 資料集劃分與動態生成機制

為了驗證模型的泛化能力並避免過度擬合（Overfitting）：

資料集劃分： 本研究主動將字符集劃分為「訓練集」與「測試集」。訓練階段僅使用特定的字符（如主動移除資料集中的 A、E、I、G、Z等隨機字符），以模擬中文資料集不包含所有文字的情況，並用以評估模型是否真正學會了「風格遷移」而非單純記憶圖像。

動態生成 (On-the-fly Generation)： 訓練資料並非預先存成靜態圖片，而是在程式運作時透過 __getitem__ 動態渲染。此機制不僅大幅節省硬碟空間，更允許我們在每一個 Epoch 對同一字符施加不同的隨機增強效果，使模型在整個訓練週期中從未看過完全相同的兩張圖片。(意即每一輪獲得的資料都不一樣)

  

3.4 幾何增強：同步變換策略

考量手寫字體在真實書寫時具有高度的隨機性，本研究引入幾何增強技術。關鍵在於採用同步變換（Synchronized Transformation），即對來源圖（Source）與目標圖（Target）施加完全相同的變換參數，以維持兩者結構的對應關係：

縮放 (Scaling)： 模擬字體大小的變化。

旋轉 (Rotation)： 模擬書寫時的傾斜角度（±θ度）。

平移 (Translation)： 模擬文字在方格內的位置偏移。

透過幾何增強，擴增數據量，讓模型遇到類似的結構能夠套用

  

3.5 隨機遮罩 (Random Masking)

為了增強模型對缺損筆畫的推論能力，本研究參考去噪自動編碼器（Denoising Autoencoder）的概念，引入隨機遮罩機制。

在訓練過程中，以特定機率 P mask 對輸入圖像及目標圖像隨機遮蔽一塊矩形區域（將像素值設為背景色）。

此舉同樣是為了讓缺少的資料能有更多樣的變化

  

3.6 生成器層數與瓶頸層架構

生成器（Generator）採用編碼器-解碼器（Encoder-Decoder）結構，並具備可調整的彈性設計：

彈性層數配置： 為了公平比較不同實驗變因，模型設計時確保在調整層數或特徵圖大小時，整體的參數量（Parameters）維持在相近的數量級。(見下表)

瓶頸層 (Bottleneck) 實驗： 架構中心設有瓶頸層，將特徵圖壓縮至 n×n(如 1x1 、4x4 等等)。此層強迫模型過濾掉非必要的雜訊，僅保留最核心的風格特徵。一般研究建議瓶頸層設為1x1，但本研究則將 bottleneck_size 設為實驗變因，探討不同壓縮率對生成品質的影響。

  

3.7 判別器架構

判別器（Discriminator）採用全卷積神經網路（Fully Convolutional Network）：

由多層卷積層（Conv2d）與 LeakyReLU 激活函數堆疊而成。

透過逐步下採樣（Down-sampling）將圖像特徵壓縮，最終輸出一個數值。

無 Sigmoid 輸出： 配合 WGAN-GP 理論，判別器的最後一層不使用 Sigmoid 函數，直接輸出未經限制的實數分數（Logits），代表圖像的真實程度評分。

  

3.8 損失函數設計

為了兼顧生成的真實感與內容正確性，總損失函數 結合了兩部分：

對抗損失 (Adversarial Loss)： 源自 WGAN-GP，促使生成圖像的分佈盡可能接近真實手寫字體的分佈。

L1 像素損失 (L1 Reconstruction Loss)： 計算生成圖與真實目標圖之間像素值的絕對誤差。

  

其中 入1 為權重參數，用於確保生成的文字在結構上與目標文字保持一致，避免字形嚴重扭曲。

  

3.9 影像形態學處理：膨脹與縮減

針對部分手寫字體筆畫過於纖細，導致在卷積過程中特徵易丟失的問題，本研究在預處理階段可引入形態學操作（Morphological Operations）：

膨脹 (Dilation)： 對目標字體進行輕微的膨脹處理，加粗筆畫線條，使其特徵在64×64 的解析度下更為顯著，有助於模型捕捉筆畫的走向與連結點。

此步驟可視為一種特徵強化的預處理手段，特別適用於鋼筆或原子筆等細字體風格的訓練。



---
藍翊庭 - Week 46
