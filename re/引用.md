
  
[1]
Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. _Advances in neural information processing systems_, _27_.

[2]
Radford, A., Metz, L., & Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. _arXiv preprint arXiv:1511.06434_.

[3]
Arjovsky, M., Chintala, S., & Bottou, L. (2017). Wasserstein generative adversarial networks. In _International conference on machine learning_ (pp. 214-223). PMLR.

[4]
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., & Courville, A. C. (2017). Improved training of wasserstein gans. _Advances in neural information processing systems_, _30_.

[5]
Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In _Proceedings of the IEEE conference on computer vision and pattern recognition_ (pp. 1125-1134).

[Image-To-Image Translation With Conditional Adversarial Networks](https://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf)

[Isola_Image-To-Image_Translation_With_CVPR_2017_paper](ref/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf)

```
We also explore this option, using L1 distance rather than L2 as L1 encourages less blurring
```

```
Conditional adversarial nets are a general-purpose solution to image-to-image translation problems
```

[6]
Tian, Y. (2017). _Zi2zi: Master Chinese Calligraphy with Conditional Adversarial Networks_. Github. https://github.com/kaonashi-tyc/zi2zi

```
zi2zi(字到字)... is an application and extension of the recent popular pix2pix model to Chinese characters... addition of category embedding
```

[7]
Wen, C., Pan, Y., Chang, J., Zhang, Y., Chen, S., Wang, Y., ... & Tian, Q. (2021). Handwritten Chinese font generation with collaborative stroke refinement. In _Proceedings of the IEEE/CVF winter conference on applications of computer vision_ (pp. 3882-3891).

[Handwritten Chinese Font Generation With Collaborative Stroke Refinement](https://openaccess.thecvf.com/content/WACV2021/papers/Wen_Handwritten_Chinese_Font_Generation_With_Collaborative_Stroke_Refinement_WACV_2021_paper.pdf)

[Wen_Handwritten_Chinese_Font_Generation_With_Collaborative_Stroke_Refinement_WACV_2021_paper](ref/Wen_Handwritten_Chinese_Font_Generation_With_Collaborative_Stroke_Refinement_WACV_2021_paper.pdf)

```
An auxiliary branch is trained to generate the bold version of target characters... we further propose an online zoom-augmentation strategy to reduce the dependency on large size training sets
```

[8]
Chen, X., Xie, Y., Sun, L., & Lu, Y. (2022). Dgfont++: Robust deformable generative networks for unsupervised font generation. _arXiv preprint arXiv:2212.14742_.

[[2212.14742] DGFont++: Robust Deformable Generative Networks for Unsupervised Font Generation](https://arxiv.org/abs/2212.14742)

[DGFont++_2212.14742v1](ref/DGFont++_2212.14742v1.pdf)

[9]
Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., & Efros, A. A. (2016). Context encoders: Feature learning by inpainting. In _Proceedings of the IEEE conference on computer vision and pattern recognition_ (pp. 2536-2544).

[Context Encoders: Feature Learning by Inpainting](https://openaccess.thecvf.com/content_cvpr_2016/papers/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf)

[Pathak_Context_Encoders_Feature_CVPR_2016_paper](ref/Pathak_Context_Encoders_Feature_CVPR_2016_paper.pdf)

```
在 5.1 節中提到 "bottleneck is of 4000 units
```

[10]
Lee, J. S., & Choi, H. C. (2024). One-shot font generation via local style self-supervision using Region-Aware Contrastive Loss. _Journal of King Saud University-Computer and Information Sciences_, _36_(4), 102028.

[One-shot font generation via local style self-supervision using Region-Aware Contrastive Loss - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S1319157824001174)

[1-s2.0-S1319157824001174-main](ref/One-shot-font-generation_1-s2.0-S1319157824001174-main.pdf)

```
In this configuration, a feature with a resolution of 16 x 16 was used to compute the RAC-loss
```

[11]
Zeng, J., Chen, Q., Liu, Y., Wang, M., & Yao, Y. (2021, May). Strokegan: Reducing mode collapse in chinese font generation via stroke encoding. In _Proceedings of the AAAI conference on artificial intelligence_ (Vol. 35, No. 4, pp. 3270-3277).

[StrokeGAN: Reducing Mode Collapse in Chinese Font Generation via Stroke Encoding | Proceedings of the AAAI Conference on Artificial Intelligence](https://ojs.aaai.org/index.php/AAAI/article/view/16438)

[16438-Article Text-19932-1-2-20210518](ref/StrokeGAN_16438-Article%20Text-19932-1-2-20210518.pdf)

```
character resized to 128x128x3... network structure of the generator... including 2 convolutional layers in the down-sampling module
```

[12]
Goldfeld, Z., & Polyanskiy, Y. (2020). The information bottleneck problem and its applications in machine learning. _IEEE Journal on Selected Areas in Information Theory_, _1_(1), 19-38.

[[2004.14941] The Information Bottleneck Problem and Its Applications in Machine Learning](https://arxiv.org/abs/2004.14941)
[2004.14941v2](ref/nformation-Bottleneck_2004.14941v2.pdf)

```
The information bottleneck (IB) theory... suggests that the best representation T should be maximally informative about Y while minimizing the mutual information with X
```

---

沒用

[[2503.02799] MX-Font++: Mixture of Heterogeneous Aggregation Experts for Few-shot Font Generation](https://arxiv.org/abs/2503.02799) 
他是那個部件拆解

[CalliFormer: a structure-aware transformer for Chinese calligraphy generation | Scientific Reports](https://www.nature.com/articles/s41598-025-29262-1)
太抽象

[運用GAN實現字體風格轉換-中華民國第58屆中小學科學展覽會](https://twsf.ntsec.gov.tw/activity/race-1/58/pdf/NPHSF2018-052511.pdf)
沒啥用